{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SynthMorph Affine PyTorch Demo\n",
    "## Purpose\n",
    "Reproduce the original affine components of SynthMorph demo in Torch.\n",
    "- Data generation with affine augmentations\n",
    "- Affine registration model training\n",
    "- Registration (inference) examples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# local code\n",
    "from synthmorph import networks, models, layers, losses, datamodule as dm, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'     # note: only gpu has been tested so far\n",
    "torch.set_default_device(device)\n",
    "# mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynthMorph Affine Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Label (i.e. Segmentation) Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shapes.\n",
    "in_shape = (256,) * 2\n",
    "num_dim = len(in_shape)\n",
    "num_label = 2\n",
    "label_map = dm.generate_map(in_shape, num_label, device=device)\n",
    "n = 4\n",
    "affine_args = dict(\n",
    "    translate=(0.15, 0.15),\n",
    "    scale=(0.5, 0.7)\n",
    ")\n",
    "gen_args = dict(\n",
    "    warp_std=0,\n",
    "    warp_res=(8, 16, 32),\n",
    "    zero_background=1,\n",
    "    affine_args=affine_args,\n",
    "    # remove later\n",
    "    mean_min=255,\n",
    "    mean_max=255,\n",
    "    std_min = 0,\n",
    "    std_max = 0,\n",
    "    bias_std=0,\n",
    "    blur_std=0,\n",
    "    gamma_std=0,\n",
    "    dc_offset=0,\n",
    ")\n",
    "\n",
    "gen = [dm.labels_to_image(label_map, **gen_args) for _ in tqdm(range(n))]\n",
    "gen_images = [g['image'] for g in gen]\n",
    "gen_labels= [g['label'] for g in gen]\n",
    "\n",
    "plot_num = min(n, 4)\n",
    "fig, axes = plt.subplots(1, plot_num, figsize=(plot_num*8, 8))\n",
    "\n",
    "for i in range(plot_num):\n",
    "    image = gen_images[i].squeeze().tolist()\n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each label of an image\n",
    "ind = 0\n",
    "image = gen_images[ind].squeeze().tolist()\n",
    "labels = gen_labels[ind].squeeze().tolist()\n",
    "plot_num = gen_labels[ind].shape[0] + 1\n",
    "fig, axes = plt.subplots(1, plot_num, figsize=(plot_num*8, 8))\n",
    "axes[0].imshow(image, cmap='gray')\n",
    "axes[0].axis('off')\n",
    "for c in range(1, plot_num):\n",
    "    ax = axes[c]\n",
    "    l = labels[c - 1]\n",
    "    ax.imshow(l, cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data generator\n",
    "size = 100\n",
    "in_shape = (256,) * 2\n",
    "num_labels = 16\n",
    "scale = (0.5, 0.7)\n",
    "affine_args = dict(\n",
    "    scale=scale,\n",
    "    translate=(round((1 - max(scale))/2, 3),) * 2\n",
    ")\n",
    "gen_args = dict(\n",
    "    warp_std=0,\n",
    "    warp_res=(8, 16, 32),\n",
    "    zero_background=1,\n",
    "    affine_args=affine_args,\n",
    "    # # remove later\n",
    "    # mean_min=255,\n",
    "    # mean_max=255,\n",
    "    # std_min = 0,\n",
    "    # std_max = 0,\n",
    "    # bias_std=0,\n",
    "    # blur_std=0,\n",
    "    # gamma_std=0,\n",
    "    # dc_offset=0,\n",
    ")\n",
    "\n",
    "train_data = dm.SMShapesDataset(\n",
    "    size=size,\n",
    "    input_size=in_shape,\n",
    "    num_labels=num_labels,\n",
    "    gen_args=gen_args,\n",
    ")\n",
    "\n",
    "# dataloader_kwargs = {\n",
    "#     'num_workers': 8,\n",
    "#     'persistent_workers': True,\n",
    "#     'pin_memory': True,\n",
    "# } if device == 'cuda' else {}\n",
    "dataloader_kwargs = {}\n",
    "\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device),\n",
    "    **dataloader_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug num workers > 0 causing ones and zeros tensors \n",
    "dataloader_out = next(iter(dataloader))[\"fixed\"]\n",
    "print(dataloader_out.abs().sum())   # should be a positive number > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can generate the Torch version of the original author's weights from tf2torch.ipynb\n",
    "# State dict weights for the registration model, different from PL checkpoint\n",
    "weights_path = Path(\".\") / 'weights'\n",
    "# reg_weights = weights_path / 'torch' / \"authors.pth\"   # 'None' for no weight loading\n",
    "reg_weights = None\n",
    "# Fresh model\n",
    "in_shape = (256,) * 2\n",
    "enc_nf = [256] * 4\n",
    "dec_nf = [256] * 0\n",
    "add_nf = [256] * 4\n",
    "model = models.SynthMorphAffine(\n",
    "    vol_size=in_shape,\n",
    "    enc_nf=enc_nf,\n",
    "    dec_nf=dec_nf,\n",
    "    add_nf=add_nf,\n",
    "    lr=1e-04,\n",
    "    reg_weights=reg_weights,\n",
    ")\n",
    "n_param = utils.torch_model_parameters(model.reg_model)\n",
    "\n",
    "# Model from checkpoint\n",
    "checkpoint_path = './lightning_logs/version_81/checkpoints/epoch=499-step=12500.ckpt'\n",
    "model = models.SynthMorphAffine.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    lr=1e-05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 500\n",
    "steps = train_data.size // dataloader.batch_size\n",
    "max_steps = max_epochs * steps\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    max_epochs=max_epochs,\n",
    "    max_steps=max_steps,\n",
    "    log_every_n_steps=steps,\n",
    "    # detect_anomaly=True\n",
    ")\n",
    "trainer.fit(model=model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Synthmorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data generator\n",
    "size = 100\n",
    "in_shape = (256,) * 2\n",
    "num_labels = 16\n",
    "scale = (0.5, 0.7)\n",
    "affine_args = dict(\n",
    "    scale=scale,\n",
    "    translate=(round((1 - max(scale))/2, 3),) * 2\n",
    ")\n",
    "gen_args = dict(\n",
    "    warp_std=0,\n",
    "    warp_res=(8, 16, 32),\n",
    "    zero_background=1,\n",
    "    affine_args=affine_args,\n",
    "    # # remove later\n",
    "    # mean_min=255,\n",
    "    # mean_max=255,\n",
    "    # std_min = 0,\n",
    "    # std_max = 0,\n",
    "    # bias_std=0,\n",
    "    # blur_std=0,\n",
    "    # gamma_std=0,\n",
    "    # dc_offset=0,\n",
    ")\n",
    "\n",
    "test_data = dm.SMShapesDataset(\n",
    "    size=size,\n",
    "    input_size=in_shape,\n",
    "    num_labels=num_labels,\n",
    "    gen_args=gen_args,\n",
    ")\n",
    "\n",
    "# dataloader_kwargs = {\n",
    "#     'num_workers': 8,\n",
    "#     'persistent_workers': True,\n",
    "#     'pin_memory': True,\n",
    "# } if device == 'cuda' else {}\n",
    "dataloader_kwargs = {}\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device),\n",
    "    **dataloader_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model from checkpoint\n",
    "checkpoint_path = './lightning_logs/version_82/checkpoints/epoch=499-step=12500.ckpt'\n",
    "model = models.SynthMorphAffine.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    ")\n",
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate dice over label maps\n",
    "eval_size = int(1e3)\n",
    "dice_arr = np.zeros(shape=(eval_size,))\n",
    "for i in tqdm(range(eval_size)):\n",
    "    gen = next(iter(test_dataloader))\n",
    "    moving = gen['moving']\n",
    "    fixed = gen['fixed']\n",
    "    moving_map = gen['moving_map']\n",
    "    fixed_map = gen['fixed_map']\n",
    "    moved, warp = model.predict_step(moving, fixed) \n",
    "    moved_map = layers.SpatialTransformer(fill_value=0)([networks.torch_to_tf(moving_map), networks.torch_to_tf(warp)])\n",
    "    moved_map = networks.tf_to_torch(moved_map.clip(0, 1).round())\n",
    "    dice = -losses.Dice().loss(fixed_map, moved_map)\n",
    "    dice_arr[i] = dice.tolist()\n",
    "dice_arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = next(iter(test_dataloader))\n",
    "moving = gen['moving']\n",
    "fixed = gen['fixed']\n",
    "moving_map = gen['moving_map']\n",
    "fixed_map = gen['fixed_map']\n",
    "moved, warp = model.predict_step(moving, fixed)\n",
    "moved_np, warp_np = dm.torch2numpy(moved), dm.torch2numpy(warp)\n",
    "moving_np, fixed_np = dm.torch2numpy(moving), dm.torch2numpy(fixed)\n",
    "movement_plot = [moving_np, fixed_np, moved_np]\n",
    "movement_headers = ['Moving', 'Fixed', 'Moved ']\n",
    "utils.plot_array_row(movement_plot, movement_headers, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_map = layers.SpatialTransformer(fill_value=0)([networks.torch_to_tf(moving_map), networks.torch_to_tf(warp)])\n",
    "moved_map = networks.tf_to_torch(moved_map).clip(0, 1).round()\n",
    "dice = -losses.Dice().loss(fixed_map, moved_map).tolist()\n",
    "\n",
    "moving_map_np = dm.torch2numpy(moving_map[:, 1:, ...].sum(dim=1))\n",
    "fixed_map_np = dm.torch2numpy(fixed_map[:, 1:, ...].sum(dim=1))\n",
    "moved_map_np = dm.torch2numpy(moved_map[:, 1:, ...].sum(dim=1))\n",
    "rgb_fixed = utils.convert_to_single_rgb(fixed_map_np, 'red')\n",
    "rgb_moving = utils.convert_to_single_rgb(moving_map_np, 'green')\n",
    "rgb_moved = utils.convert_to_single_rgb(moved_map_np, 'blue')\n",
    "overlay_before = utils.overlay_images(rgb_fixed, rgb_moving)\n",
    "overlay_after = utils.overlay_images(rgb_fixed, rgb_moved)\n",
    "movement_plot = [overlay_before, overlay_after]\n",
    "movement_headers = ['Moving (green) and Fixed (red)', f'Fixed (red) and Moved (blue)\\nDice: {dice:.4f}']\n",
    "utils.plot_array_row(movement_plot, movement_headers, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.reg_model(moving, fixed)\n",
    "moving_keypoints = dm.torch2numpy(results['com_1'])\n",
    "fixed_keypoints = dm.torch2numpy(results['com_2'])\n",
    "keypoints = [moving_keypoints, fixed_keypoints]\n",
    "headers = [\"Moving\", \"Fixed\"]\n",
    "x_mid = in_shape[0] // 2\n",
    "y_mid = in_shape[1] // 2\n",
    "utils.plot_keypoints(keypoints, headers, xlim=(-x_mid, x_mid), ylim=(-y_mid, y_mid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superimposed circles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background for circles\n",
    "size = 40\n",
    "in_shape = (256,) * 2\n",
    "num_labels = 16\n",
    "# Note: affine transformations are not needed du\n",
    "gen_args = dict(\n",
    "    warp_std=0, # no deformable\n",
    "    warp_res=(8, 16, 32),   # ignore when warp_std=0\n",
    "    zero_background=1,\n",
    "    mean_max=200,   # Prevent sharing too similar intensities as circles (e.g. 255)\n",
    "    affine_args=None\n",
    ")\n",
    "\n",
    "bg_data = dm.SMShapesDataset(\n",
    "    size=size,\n",
    "    input_size=in_shape,\n",
    "    num_labels=num_labels,\n",
    "    gen_args=gen_args,\n",
    ")\n",
    "\n",
    "dataloader_kwargs = {\n",
    "    'num_workers': 0,\n",
    "    # 'persistent_workers': True,\n",
    "    # 'pin_memory': True,\n",
    "} if device == 'cuda' else {}\n",
    "\n",
    "\n",
    "bg_dataloader = DataLoader(\n",
    "    dataset=bg_data,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device),\n",
    "    **dataloader_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random image-mask pairs for moving and fixed\n",
    "bg = next(iter(bg_dataloader))\n",
    "\n",
    "moving_superimpose = lambda moving: utils.superimpose_circles(\n",
    "    moving, \n",
    "    pixel_value=255, \n",
    "    size_range=(0.030, 0.030), \n",
    "    dist_range=(50, 51), \n",
    "    rotate=0,\n",
    "    x_shift=0,\n",
    "    y_shift=0,\n",
    ")\n",
    "moving = moving_superimpose(dm.torch2numpy(bg['moving']))\n",
    "moving = moving_superimpose(np.zeros(in_shape))\n",
    "moving_map = moving_superimpose(np.zeros(in_shape))\n",
    "\n",
    "fixed_superimpose = lambda fixed: utils.superimpose_circles(\n",
    "    fixed, \n",
    "    pixel_value=255, \n",
    "    size_range=(0.030, 0.030), \n",
    "    dist_range=(50, 51), \n",
    "    rotate=0,\n",
    "    x_shift=5,\n",
    "    y_shift=5,\n",
    ")\n",
    "fixed = fixed_superimpose(dm.torch2numpy(bg['fixed']))\n",
    "fixed = fixed_superimpose(np.zeros(in_shape))\n",
    "fixed_map = fixed_superimpose(np.zeros(in_shape))\n",
    "\n",
    "moving = dm.conform(x=moving, in_shape=in_shape, device=device)\n",
    "fixed = dm.conform(x=fixed, in_shape=in_shape, device=device)\n",
    "\n",
    "moved, warp = model.predict_step(moving, fixed)\n",
    "moved, warp = dm.torch2numpy(moved), dm.torch2numpy(warp)\n",
    "# post-process for plotting\n",
    "moving, fixed = dm.torch2numpy(moving.squeeze()), dm.torch2numpy(fixed.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_plot = [moving, fixed, moved]\n",
    "movement_headers = ['Moving', 'Fixed', 'Moved']\n",
    "utils.plot_array_row(movement_plot, movement_headers, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels here are supposed to be the circles only,\n",
    "#  ignore areas which share the same value\n",
    "rgb_fixed = utils.convert_to_single_rgb(fixed, 'red')\n",
    "rgb_moving = utils.convert_to_single_rgb(moving, 'green')\n",
    "rgb_moved = utils.convert_to_single_rgb(moved, 'blue')\n",
    "\n",
    "overlay_before = utils.overlay_images(rgb_fixed, rgb_moving)\n",
    "overlay_after = utils.overlay_images(rgb_fixed, rgb_moved)\n",
    "\n",
    "overlay_plot = [overlay_before, overlay_after,]\n",
    "overlay_headers = ['Fixed and Moving', 'Fixed and Moved']\n",
    "utils.plot_array_row(overlay_plot, overlay_headers, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthmorph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
