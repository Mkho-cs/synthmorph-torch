{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF to Torch Conversion\n",
    "\n",
    "## Purpose\n",
    "- Weight transfer\n",
    "- Torch reproducibility\n",
    "- Torch debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p6kExhij7_gs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import gdown\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neurite as ne\n",
    "import voxelmorph as vxm\n",
    "\n",
    "from torch import nn\n",
    "from tensorflow.keras.models import Model\n",
    "from skimage.metrics import structural_similarity\n",
    "\n",
    "# local code\n",
    "from synthmorph import layers, networks, datamodule as dm, utils\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # note: only gpu has been tested so far\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prevent TF model from taking whole GPU memory\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deformable Registration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Weights TF -> Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define fresh Keras model, only for loading original author's weights\n",
    "# This section is just a copy of the orginal demo to define the Keras model\n",
    "\n",
    "# Label maps\n",
    "in_shape = (256,) * 2\n",
    "num_dim = len(in_shape)\n",
    "num_label = 16\n",
    "num_maps = 1\n",
    "label_maps = []\n",
    "for _ in range(num_maps):\n",
    "    # Draw image and warp.\n",
    "    im = ne.utils.augment.draw_perlin(\n",
    "        out_shape=(*in_shape, num_label),\n",
    "        scales=(32, 64), max_std=1,\n",
    "    )\n",
    "    warp = ne.utils.augment.draw_perlin(\n",
    "        out_shape=(*in_shape, num_label, num_dim),\n",
    "        scales=(16, 32, 64), max_std=16,\n",
    "    )\n",
    "\n",
    "    # Transform and create label map.\n",
    "    im = vxm.utils.transform(im, warp)\n",
    "    lab = tf.argmax(im, axis=-1)\n",
    "    label_maps.append(np.uint8(lab))\n",
    "\n",
    "# Image generator\n",
    "gen_arg = dict(\n",
    "    in_shape=in_shape,\n",
    "    in_label_list=np.unique(label_maps),\n",
    "    warp_std=3,\n",
    "    warp_res=(8, 16, 32),\n",
    ")\n",
    "gen_model_1 = ne.models.labels_to_image(**gen_arg, id=1)\n",
    "gen_model_2 = ne.models.labels_to_image(**gen_arg, id=2)\n",
    "\n",
    "# Registration model.\n",
    "reg_model = vxm.networks.VxmDense(\n",
    "    inshape=in_shape,\n",
    "    int_resolution=2,\n",
    "    svf_resolution=2,\n",
    "    nb_unet_features=([256] * 4, [256] * 8),\n",
    "    reg_field='warp',\n",
    ")\n",
    "\n",
    "# Model for optimization.\n",
    "ima_1, map_1 = gen_model_1.outputs\n",
    "ima_2, map_2 = gen_model_2.outputs\n",
    "\n",
    "_, warp = reg_model((ima_1, ima_2))\n",
    "pred = vxm.layers.SpatialTransformer(fill_value=0)((map_1, warp))\n",
    "\n",
    "inputs = gen_model_1.inputs + gen_model_2.inputs\n",
    "out = (map_2, pred)\n",
    "model = tf.keras.Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Keras pretrained weights\n",
    "gdown.download('https://drive.google.com/uc?id=1xridvtyEWgWsWJPYVrQfDCtSgbj2beRz', 'weights.h5')\n",
    "model.load_weights('weights.h5')\n",
    "\n",
    "# Extract weights from the registration model only\n",
    "keras_vxmdense = reg_model   \n",
    "keras_weights = {w.name: (w.numpy(), w.dtype, w.shape) for w in keras_vxmdense.weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only get kernel weight (ie. skip biases)\n",
    "keras_weights_keys = list(keras_weights.keys())\n",
    "keras_kernels = [string for string in keras_weights_keys if 'bias' not in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fresh Torch model\n",
    "vol_size = (256,) * 2\n",
    "unet_enc_nf = [256] * 4\n",
    "unet_dec_nf = [256] * 8\n",
    "int_steps = 7 \n",
    "int_downsize = 2\n",
    "bidir = False\n",
    "torch_vxmdense = networks.VxmDense(\n",
    "    inshape=vol_size,\n",
    "    nb_unet_features=[unet_enc_nf, unet_dec_nf],\n",
    "    int_steps=int_steps,\n",
    "    int_downsize=int_downsize,\n",
    "    bidir=bidir,\n",
    "    unet_half_res=True,\n",
    ")\n",
    "\n",
    "torch_weights = torch_vxmdense.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the same model in Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = {}\n",
    "\n",
    "# Transfer the weights (the order of layers are the same)\n",
    "for k,t in zip(keras_weights.keys(), torch_weights.keys()):\n",
    "    if k in keras_kernels:\n",
    "        new_weights[t] = torch.Tensor(np.moveaxis(keras_weights[k][0], [-1, -2], [0, 1]))\n",
    "    else:\n",
    "        new_weights[t] = torch.Tensor(keras_weights[k][0])\n",
    "\n",
    "torch_vxmdense.load_state_dict(new_weights)\n",
    "# torch.save(torch_vxmdense.state_dict(), Path(\".\") / 'authors.pth' )  # uncomment to save weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Reimplementation Debug\n",
    "Make sure that both TF and Torch models are using the same weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preprocessing for TF\n",
    "def tf_conform(x, in_shape=in_shape):\n",
    "    '''Resize and normalize image.'''\n",
    "    x = np.float32(x)\n",
    "    x = np.squeeze(x)\n",
    "    x = ne.utils.minmax_norm(x)\n",
    "    x = ne.utils.zoom(x, zoom_factor=[o / i for o, i in zip(in_shape, x.shape)])\n",
    "    return np.expand_dims(x, axis=(0, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load MNIST in TF\n",
    "images, digits = tf.keras.datasets.mnist.load_data()[-1]\n",
    "ind = np.flatnonzero(digits == 6)\n",
    "moving = tf_conform(images[ind[256]])\n",
    "fixed = tf_conform(images[ind[22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preprocessing for Torch\n",
    "torch_conform = lambda x, size: dm.conform(x, size, device) \n",
    "torch_moving = torch_conform(moving, (256,256))\n",
    "torch_fixed = torch_conform(fixed, (256,256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load TF layers by indexing\n",
    "custom_keras_layers = keras_vxmdense.layers[:]\n",
    "custom_keras_model= Model(\n",
    "    inputs=keras_vxmdense.inputs, \n",
    "    outputs=custom_keras_layers[-1].output    # output from chosen layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Torch layers by specifying each module\n",
    "# Note: SpatialTransformer is not compatible with nn.Sequential, hence separated\n",
    "unet_torch = torch_vxmdense.unet_model\n",
    "flow_torch = torch_vxmdense.flow\n",
    "vecint_torch = torch_vxmdense.integrate\n",
    "rescale_torch = torch_vxmdense.fullsize\n",
    "spatial_torch = torch_vxmdense.transformer\n",
    "custom_torch_model = nn.Sequential(\n",
    "    unet_torch, \n",
    "    flow_torch,\n",
    "    vecint_torch,\n",
    "    rescale_torch,\n",
    ")\n",
    "custom_torch_model = custom_torch_model.eval().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SSIM of TF vs Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare chosen output from TF and Torch registration models\n",
    "keras_output = custom_keras_model.predict((moving, fixed))\n",
    "keras_output = keras_output.transpose(0, 3, 1, 2).squeeze(0)\n",
    "\n",
    "torch_input = torch.cat([torch_moving, torch_fixed], dim=1)\n",
    "torch_output = custom_torch_model(torch_input)\n",
    "torch_output = spatial_torch([torch_moving, torch_output]) # uncomment only when comparing moved image (i.e. whole reg model)\n",
    "torch_output = torch_output.squeeze(0).cpu().detach().numpy()\n",
    "\n",
    "data_range = torch_output.max() - torch_output.min()\n",
    "channel_axis = 0 if torch_output.ndim > 2 else None\n",
    "ssim_mean, ssim_full= structural_similarity(\n",
    "    torch_output, \n",
    "    keras_output,\n",
    "    win_size=11,    # must be odd\n",
    "    data_range=data_range,\n",
    "    channel_axis=0,\n",
    "    multichannel=True,\n",
    "    full=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each axis of resulting SSIM\n",
    "num_plots = ssim_full.shape[0]\n",
    "plot_scale = 6\n",
    "fig, axs = plt.subplots(1, num_plots, figsize=(plot_scale*num_plots, plot_scale), squeeze=False)   # subplots in  one row\n",
    "fig.suptitle(f\"SSIM Plot for each channel, Mean = {ssim_mean*100:.4f}\")\n",
    "for i in range(num_plots):\n",
    "    ax = axs[0, i]\n",
    "    im = ax.imshow(ssim_full[i], cmap='gray')\n",
    "    ax.set_title(f'Channel {i+1}')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference time TF vs PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "width, height = 256, 256\n",
    "channel = 1\n",
    "batch_size = 1\n",
    "shape = (batch_size, width, height, channel)\n",
    "moving = rng.standard_normal(size=shape)\n",
    "fixed = rng.standard_normal(size=shape)\n",
    "\n",
    "prepare_torch = lambda x: torch.from_numpy(x).to(device, torch.float32).permute(0, -1, 1, 2)\n",
    "torch_moving = prepare_torch(moving)\n",
    "torch_fixed = prepare_torch(fixed)\n",
    "\n",
    "tf_moving = tf.constant(moving)\n",
    "tf_fixed = tf.constant(fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100 -r 10 -p 4 \n",
    "keras_vxmdense.predict((tf_moving, tf_fixed), verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100 -r 10 -p 4\n",
    "torch_vxmdense(torch_moving, torch_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer weights TF -> Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Keras pretrained weights\n",
    "keras_weights_path = Path(\".\") / \"weights\" / \"keras\"\n",
    "affine_weights = keras_weights_path / \"affine_author_2d_256.h5\"\n",
    "# gdown.download('https://drive.google.com/uc?id=1DWiVxCvQmYDSBS1RcVbUeTxX0XArQsGv', affine_weights)\n",
    "\n",
    "in_shape = (256,) * 2\n",
    "keras_model= vxm.networks.VxmAffineFeatureDetector(in_shape)\n",
    "keras_model.load_weights(affine_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vxm_affine_feature_detector_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_10 (TFO  (4,)                         0         ['input_4[0][0]']             \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_10[0][0]'\n",
      " 0 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.repeat_6 (TFOpLambda)    (None, 2, 3)                 0         ['tf.__operators__.getitem_20[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " spatial_transformer_2 (Spa  (None, 128, 128, 1)          0         ['input_4[0][0]',             \n",
      " tialTransformer)                                                    'tf.repeat_6[0][0]']         \n",
      "                                                                                                  \n",
      " model_3 (Functional)        (None, 8, 8, 64)             4280640   ['spatial_transformer_2[0][0]'\n",
      "                                                                    , 'spatial_transformer_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (  (None, 64, 8, 8)             0         ['model_3[0][0]']             \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLamb  (None, 64, 8, 8, 1)          0         ['tf.compat.v1.transpose_2[0][\n",
      " da)                                                                0]']                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLa  (None, 64, 8, 8, 2)          0         ['tf.expand_dims_4[0][0]']    \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_11 (TFO  (4,)                         0         ['spatial_transformer_2[0][0]'\n",
      " pLambda)                                                           ]                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_8 (TFOp  (None, 64, 2)                0         ['tf.math.multiply_8[0][0]']  \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_9 (TFOp  (None, 64, 1)                0         ['tf.expand_dims_4[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_11[0][0]'\n",
      " 1 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.math.divide_no_nan_2 (T  (None, 64, 2)                0         ['tf.math.reduce_sum_8[0][0]',\n",
      " FOpLambda)                                                          'tf.math.reduce_sum_9[0][0]']\n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " tf.repeat_7 (TFOpLambda)    (None, 2, 3)                 0         ['tf.__operators__.getitem_21[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLa  (None, 64, 2)                0         ['tf.math.divide_no_nan_2[0][0\n",
      " mbda)                                                              ]']                           \n",
      "                                                                                                  \n",
      " spatial_transformer_3 (Spa  (None, 128, 128, 1)          0         ['input_5[0][0]',             \n",
      " tialTransformer)                                                    'tf.repeat_7[0][0]']         \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_13 (TFO  (3,)                         0         ['tf.math.multiply_9[0][0]']  \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (2,)                         0         ['tf.compat.v1.shape_13[0][0]'\n",
      " 4 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_12 (TFO  (None, 64)                   0         ['model_3[0][0]']             \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_13 (TFO  (None, 64)                   0         ['model_3[1][0]']             \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.concat_14 (TFOpLambda)   (3,)                         0         ['tf.__operators__.getitem_24[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_14 (TFO  (None, 1)                    0         ['tf.math.reduce_sum_12[0][0]'\n",
      " pLambda)                                                           ]                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_15 (TFO  (None, 1)                    0         ['tf.math.reduce_sum_13[0][0]'\n",
      " pLambda)                                                           ]                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_3 (  (None, 64, 8, 8)             0         ['model_3[1][0]']             \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.ones_5 (TFOpLambda)      (None, 64, 1)                0         ['tf.concat_14[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.truediv_2 (TFOpLam  (None, 64)                   0         ['tf.math.reduce_sum_12[0][0]'\n",
      " bda)                                                               , 'tf.math.reduce_sum_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.truediv_3 (TFOpLam  (None, 64)                   0         ['tf.math.reduce_sum_13[0][0]'\n",
      " bda)                                                               , 'tf.math.reduce_sum_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLamb  (None, 64, 8, 8, 1)          0         ['tf.compat.v1.transpose_3[0][\n",
      " da)                                                                0]']                          \n",
      "                                                                                                  \n",
      " tf.concat_15 (TFOpLambda)   (None, 64, 3)                0         ['tf.math.multiply_9[0][0]',  \n",
      "                                                                     'tf.ones_5[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpL  (None, 64)                   0         ['tf.math.truediv_2[0][0]',   \n",
      " ambda)                                                              'tf.math.truediv_3[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpL  (None, 64, 8, 8, 2)          0         ['tf.expand_dims_5[0][0]']    \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.linalg.matrix_transpose  (None, 3, 64)                0         ['tf.concat_15[0][0]']        \n",
      " _6 (TFOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_7 (TFOpLamb  (None, 1, 64)                0         ['tf.math.multiply_12[0][0]'] \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_10 (TFO  (None, 64, 2)                0         ['tf.math.multiply_10[0][0]'] \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_11 (TFO  (None, 64, 1)                0         ['tf.expand_dims_5[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpL  (None, 3, 64)                0         ['tf.linalg.matrix_transpose_6\n",
      " ambda)                                                             [0][0]',                      \n",
      "                                                                     'tf.expand_dims_7[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.divide_no_nan_3 (T  (None, 64, 2)                0         ['tf.math.reduce_sum_10[0][0]'\n",
      " FOpLambda)                                                         , 'tf.math.reduce_sum_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_9 (TFOpLa  (None, 3, 3)                 0         ['tf.math.multiply_14[0][0]', \n",
      " mbda)                                                               'tf.concat_15[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpL  (None, 64, 2)                0         ['tf.math.divide_no_nan_3[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.linalg.inv_5 (TFOpLambd  (None, 3, 3)                 0         ['tf.linalg.matmul_9[0][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_12 (TFO  (3,)                         0         ['tf.math.multiply_11[0][0]'] \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_10 (TFOpL  (None, 3, 64)                0         ['tf.linalg.inv_5[0][0]',     \n",
      " ambda)                                                              'tf.math.multiply_14[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (2,)                         0         ['tf.compat.v1.shape_12[0][0]'\n",
      " 2 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_11 (TFOpL  (None, 3, 2)                 0         ['tf.linalg.matmul_10[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_11[0][0]'] \n",
      "                                                                                                  \n",
      " tf.concat_12 (TFOpLambda)   (3,)                         0         ['tf.__operators__.getitem_22[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.linalg.matrix_transpose  (None, 2, 3)                 0         ['tf.linalg.matmul_11[0][0]'] \n",
      " _7 (TFOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.ones_4 (TFOpLambda)      (None, 64, 1)                0         ['tf.concat_12[0][0]']        \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_14 (TFO  (3,)                         0         ['tf.linalg.matrix_transpose_7\n",
      " pLambda)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.concat_13 (TFOpLambda)   (None, 64, 3)                0         ['tf.math.multiply_11[0][0]', \n",
      "                                                                     'tf.ones_4[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (1,)                         0         ['tf.compat.v1.shape_14[0][0]'\n",
      " 6 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (1,)                         0         ['tf.compat.v1.shape_14[0][0]'\n",
      " 7 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.linalg.matrix_transpose  (None, 3, 64)                0         ['tf.concat_13[0][0]']        \n",
      " _4 (TFOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLamb  (None, 1, 64)                0         ['tf.math.multiply_12[0][0]'] \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.concat_16 (TFOpLambda)   (3,)                         0         ['tf.__operators__.getitem_26[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_27[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.concat_17 (TFOpLambda)   (3,)                         0         ['tf.__operators__.getitem_26[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpL  (None, 3, 64)                0         ['tf.linalg.matrix_transpose_4\n",
      " ambda)                                                             [0][0]',                      \n",
      "                                                                     'tf.expand_dims_6[0][0]']    \n",
      "                                                                                                  \n",
      " tf.zeros_2 (TFOpLambda)     (None, 1, 2)                 0         ['tf.concat_16[0][0]']        \n",
      "                                                                                                  \n",
      " tf.ones_6 (TFOpLambda)      (None, 1, 1)                 0         ['tf.concat_17[0][0]']        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_6 (TFOpLa  (None, 3, 3)                 0         ['tf.math.multiply_13[0][0]', \n",
      " mbda)                                                               'tf.concat_13[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_18 (TFOpLambda)   (None, 1, 3)                 0         ['tf.zeros_2[0][0]',          \n",
      "                                                                     'tf.ones_6[0][0]']           \n",
      "                                                                                                  \n",
      " tf.linalg.inv_4 (TFOpLambd  (None, 3, 3)                 0         ['tf.linalg.matmul_6[0][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat_19 (TFOpLambda)   (None, 3, 3)                 0         ['tf.linalg.matrix_transpose_7\n",
      "                                                                    [0][0]',                      \n",
      "                                                                     'tf.concat_18[0][0]']        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_7 (TFOpLa  (None, 3, 64)                0         ['tf.linalg.inv_4[0][0]',     \n",
      " mbda)                                                               'tf.math.multiply_13[0][0]'] \n",
      "                                                                                                  \n",
      " tf.linalg.inv_6 (TFOpLambd  (None, 3, 3)                 0         ['tf.concat_19[0][0]']        \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_8 (TFOpLa  (None, 3, 2)                 0         ['tf.linalg.matmul_7[0][0]',  \n",
      " mbda)                                                               'tf.math.multiply_9[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_16 (TFO  (4,)                         0         ['spatial_transformer_2[0][0]'\n",
      " pLambda)                                                           ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 2, 3)                 0         ['tf.linalg.inv_6[0][0]']     \n",
      " 0 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.linalg.matrix_transpose  (None, 2, 3)                 0         ['tf.linalg.matmul_8[0][0]']  \n",
      " _5 (TFOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_17 (TFO  (4,)                         0         ['spatial_transformer_2[0][0]'\n",
      " pLambda)                                                           ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  ()                           0         ['tf.compat.v1.shape_16[0][0]'\n",
      " 6 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 2, 3)                 0         ['tf.__operators__.getitem_30[\n",
      " OpLambda)                                                          0][0]',                       \n",
      "                                                                     'tf.linalg.matrix_transpose_5\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  ()                           0         ['tf.compat.v1.shape_17[0][0]'\n",
      " 7 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.repeat_8 (TFOpLambda)    (None, 2, 3)                 0         ['tf.__operators__.getitem_36[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpL  (None, 2, 3)                 0         ['tf.__operators__.add_1[0][0]\n",
      " ambda)                                                             ']                            \n",
      "                                                                                                  \n",
      " tf.repeat_9 (TFOpLambda)    (None, 2, 3)                 0         ['tf.__operators__.getitem_37[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " compose_transform_2 (Compo  (None, 2, 3)                 0         ['tf.repeat_8[0][0]',         \n",
      " seTransform)                                                        'tf.math.multiply_15[0][0]', \n",
      "                                                                     'tf.repeat_9[0][0]']         \n",
      "                                                                                                  \n",
      " affine_to_dense_shift_2 (A  (None, 256, 256, 2)          0         ['compose_transform_2[0][0]'] \n",
      " ffineToDenseShift)                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4280640 (16.33 MB)\n",
      "Trainable params: 4280640 (16.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get kernel weights (ie. skip biases)\n",
    "keras_weights = {w.name: (w.numpy(), w.dtype, w.shape) for w in keras_model.weights}\n",
    "keras_weights_keys = list(keras_weights.keys())\n",
    "keras_kernels = [string for string in keras_weights_keys if 'bias' not in string]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF to Torch functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.gather(params, indices, axis, batch_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = rng.random((3, 3,))\n",
    "ind = (1,)\n",
    "axis = -1\n",
    "tf_gather = tf.gather(params, ind, axis=axis)\n",
    "torch_gather = params[..., ind]\n",
    "np.all(tf_gather == torch_gather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
